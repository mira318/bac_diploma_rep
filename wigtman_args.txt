aa: rand-m7-mstd0.5-inc1
amp: true
apex_amp: false
aug_repeats: 3 -- ?
aug_splits: 0
batch_size: 512
bce_loss: true
bce_target_thresh: 0.2
bn_eps: null
bn_momentum: null
bn_tf: false
channels_last: true
checkpoint_hist: 10 -- drawing?
clip_grad: null
clip_mode: norm
color_jitter: 0.4
cooldown_epochs: 10 -- yes, its default
crop_pct: 0.95 -- here, default = None
cutmix: 1.0
cutmix_minmax: null
data_dir: /imagenet/
dataset: ''
decay_epochs: 100 -- bad, but default -- you shouldn't think about it
decay_rate: 0.1 -- its default
dist_bn: reduce -- its default
drop: 0.0
drop_block: null
drop_connect: null
drop_path: 0.05 -- done
epoch_repeats: 0.0 -- its default
epochs: 299 -- IMPORTANT!!!
eval_metric: top1
experiment: ''
gp: null
hflip: 0.5 -- its default
img_size: null
initial_checkpoint: ''
input_size: null
interpolation: ''
jsd_loss: false
local_rank: 0 -- its default
log_interval: 50 -- its default
log_wandb: false
lr: 0.005 -- done
lr_cycle_decay: 0.5 -- its default
lr_cycle_limit: 1 -- its default
lr_cycle_mul: 1.0 -- its default
lr_k_decay: 1.0 -- its default
lr_noise: null
lr_noise_pct: 0.67 -- its default
lr_noise_std: 1.0 --its default
mean: null
min_lr: 1.0e-06 -- its default
mixup: 0.1 -- done
mixup_mode: batch -- its default
mixup_off_epoch: 0 
mixup_prob: 1.0 -- its default
mixup_switch_prob: 0.5 -- its default
model: resnet50
model_ema: false
model_ema_decay: 0.9998 -- its defaults
model_ema_force_cpu: false
momentum: 0.9 -- its default
native_amp: false
no_aug: false
no_prefetcher: false
no_resume_opt: false
num_classes: null
opt: fusedlamb -- decided to lamb
opt_betas: null
opt_eps: null
output: ''
patience_epochs: 10 -- its default
pin_mem: false
pretrained: false -- its default
ratio:
- 0.75
- 1.3333333333333333 -- its default, yes both
recount: 1 -- its default
recovery_interval: 0
remode: pixel -- done
reprob: 0.0 -- done
resplit: false
resume: ''
save_images: false
scale:
- 0.08
- 1.0 -- its default, yes both
sched: cosine -- done
seed: 0 -- carefully, default is 42
smoothing: 0.0 -- carefully default is 0.1
split_bn: false -- made default false myself
start_epoch: null
std: null
sync_bn: false -- made default false myself
torchscript: false -- made default false myself
train_interpolation: bicubic -- there, be carefull default is random
train_split: train -- its default
tta: 0
use_multi_epochs_loader: false
val_split: validation -- its default
validation_batch_size: null -- also known as vb
vflip: 0.0
warmup_epochs: 5 -- IMPORTANT!!!
warmup_lr: 0.0001 -- its default
weight_decay: 0.02 -- done 
workers: 8 -- ? скорее всего ноут не может больше четырёх
